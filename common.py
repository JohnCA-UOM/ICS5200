import json
import os
import pathlib
import pickle
import time

import bcrypt
import httpx

import chromadb
from chromadb.utils import embedding_functions

from langchain.prompts import load_prompt
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores.chroma import Chroma

import openai

# Load API key from environment variable or configuration file
os.environ["OPENAI_API_KEY"] = "ENTER KEY HERE"


""" If Path doesn't exist, then create it """
def check_path_or_create(path):
    # If Path doesn't exist, then create it
    if not os.path.exists(path):
        # Create Path defined in input
        os.makedirs(path)
        print(f"Path '{path}' created.")
    # Else, Do Nothing
    else:
        print(f"Path '{path}' already exists.")


""" Create File if it doesn't exist """
def create_file_if_not_exists(path):
    # If Path Doesn't exist, then create it
    if not os.path.isfile(path):
        # Open file using Write
        with open(path, 'w') as file:
            # Creates an empty .txt file
            pass
        print(f"File '{path}' created.")
    # Else, Do Nothing
    else:
        print(f"File '{path}' already exists.")


""" Save Data to Pickle """
def dump_to_pickle(path, data):
    # Create file found in path if it doesn't exist
    create_file_if_not_exists(path)

    # Open file for writing
    with open(path, 'wb') as file:
        # Save data to defined pickle file
        pickle.dump(data, file)


""" Load Data from a Pickle """
def load_from_pickle(path):
    # Open given Path
    with open(path, 'rb') as file:
        # Load Pickle
        data = pickle.load(file)

        # Return data loaded from Pickle
        return data


""" Loads Prompt from File and Runs Model using Prompt """
async def load_and_run_prompt(prompt_file,
                              print_prompt=False,
                              model_name="gpt-4-1106-preview",
                              temperature=0.2,
                              max_tokens_limit=512,
                              stop_sequences=None,
                              top_p=1,
                              frequency_penalty=0,
                              presence_penalty=0,
                              **kwargs):

    if stop_sequences is None:
        stop_sequences = ["\n"]

    # Get Parent Path
    path = pathlib.Path(__file__).parent.resolve()

    # Load Prompt File given Name
    prompt = load_prompt(f'{path}/resources/prompt_templates/{prompt_file}')

    # Format Prompt given **kwargs defined in input
    printed_prompt = prompt.format(**kwargs)

    # Prints prompt when True (For Debugging)
    if print_prompt:
        print(printed_prompt)

    # URL for Chat Completions
    url = "https://api.openai.com/v1/chat/completions?"
    # Header containing OpenAI Auth Token and Content Type
    headers = {
        "Authorization": f"Bearer {os.getenv('OPENAI_API_KEY')}",
        "Content-Type": "application/json",
    }
    # Payload containing model parameters and prompt
    payload = {
        "model": model_name,
        "messages": [{"role": "system", "content": printed_prompt}],
        "temperature": temperature,
        "max_tokens": max_tokens_limit,
        "stop": stop_sequences,
        "top_p": top_p,
        "frequency_penalty": frequency_penalty,
        "presence_penalty": presence_penalty,
    }

    try:
        # Create Asynchronous HTTP Client
        async with httpx.AsyncClient() as client:
            # Set timeout to 20 Seconds due to instances of prompting taking long to return
            timeout = httpx.Timeout(20)

            # Send POST request using given data
            response = await client.post(url, headers=headers, data=json.dumps(payload), timeout=timeout)

            # Return Response Generated by Model
            return {'valid': True, 'response': response.json()['choices'][0]['message']['content'] }

    # If Timed Out, then return not valid
    except httpx.ReadTimeout:
        return {'valid': False, 'response': 'Timed Out, please Try Again.'}


""" Runs Prompt and Converts it to Dictionary """
async def run_prompt_and_convert_to_obj(prompt_file,
                                        temperature=0.2,
                                        max_tokens_limit=512,
                                        model_name="gpt-4-1106-preview",
                                        print_prompt=False,
                                        **kwargs):

    json_to_obj_resp = {}
    error_count = 0

    time_start = round(time.time(), 3)

    # Error Count due to Generated Responses not always being in Correct Format
    while error_count != 3:
        # Pass down parameters inputted above and go through process of generated a response
        response = await load_and_run_prompt(prompt_file,
                                             temperature=temperature,
                                             max_tokens_limit=max_tokens_limit,
                                             model_name=model_name,
                                             print_prompt=print_prompt,
                                             **kwargs)

        if response['valid']:
            # If Generated Response is valid, the convert from JSON to Object
            json_to_obj_resp = await convert_json_to_object(response['response'])

            # If Successfully converted JSON to Object, then
            if json_to_obj_resp['valid']:
                break

            print('-----')
            print(response)
            print('-----')

        # If not valid, then add Error Count
        error_count += 1

    # If not valid after running prompt 3 times, then return not valid
    if not json_to_obj_resp['valid']:
        return {'valid': False, 'response': f'Error Occurred after trying to run Prompt File 3 times: {prompt_file}'}
    # Else, Return Valid with Converted Response
    else:
        return json_to_obj_resp


""" Convert JSON into a Dictionary """
async def convert_json_to_object(prompt_resp):
    try:
        # Convert JSON to Dictionary
        prompt_resp = json.loads(prompt_resp)

        # If No Errors occurred, return converted Dictionary
        return {'valid': True, 'response': prompt_resp}
    except:
        print('ERROR OCCURRED RUNNING: ', prompt_resp)

        # If any error occurs, return not valid
        return {'valid': False, 'response': 'Error Occurred parsing Prompt Response'}


""" Initialises the ChromaDB Connection """
def init_chromadb_connections(path, collection_name, model_name):
    # Define ChromaDB Client Path using inputted Path
    chromadb_client = chromadb.PersistentClient(path=path)

    # Create / Get ChromaDB Collection given Name and Model
    collection = chromadb_client.get_or_create_collection(name=collection_name,
                                                          embedding_function=embedding_functions.OpenAIEmbeddingFunction(
                                                              api_key=os.getenv('OPENAI_API_KEY'),
                                                              model_name=model_name
                                                          ),
                                                          metadata={"hnsw:space": "cosine"})

    # Pass Chroma Client into Langchain
    langchain_chroma = Chroma(
        client=chromadb_client,
        collection_name=collection_name,
        embedding_function=OpenAIEmbeddings(),
    )

    return collection, langchain_chroma, chromadb_client


""" Checks User Inputted Password with the Hashed Password saved to File """
def checkPassword(thisPass, hashedPass):
    # Encode User Inputted Password into utf-8
    b = thisPass.encode("utf-8")

    try:
        # Checks User Inputted Password with Hashed Password saved in File
        check_pw_result = bcrypt.checkpw(b, hashedPass)

        # Set correct_pass based on whether User Inputted Password == Hashed Password
        res = {'valid': True, 'correct_pass': check_pw_result}
    except:
        # If Error Encountered, then automatically set to not valid
        res = {'valid': False}

    return res
